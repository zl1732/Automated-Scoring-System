{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utlis import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import string\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _cleanText(t):\n",
    "    '''\n",
    "    t string, raw text input\n",
    "    ret t string, a list of words\n",
    "    '''\n",
    "    t = t.lower()\n",
    "    t = re.sub(r'[^\\w\\s]','',t)\n",
    "    t = re.sub(r'\\s*(\\(\\d)|(\\))\\s*', '', t)\n",
    "    #t = t.split()\n",
    "    return t\n",
    "\n",
    "def _nltktag(text):\n",
    "    \"\"\"\n",
    "    Using nltk.word_tokenize to tag words as 'NN', 'DT'\n",
    "    for extracting noun, verb, adj\n",
    "    \"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    tagged_words = pos_tag(words)\n",
    "    return tagged_words\n",
    "\n",
    "def _wordCount(text):\n",
    "    \"\"\"\n",
    "    input: string \n",
    "    output: int -- Count of words\n",
    "    \"\"\"\n",
    "    return sum(Counter(text.split()).values())\n",
    "\n",
    "def _longWordCount(text):\n",
    "    \"\"\"\n",
    "    input: string\n",
    "    output: int -- Count of Long words\n",
    "    \n",
    "    \"\"\"\n",
    "    #Average word length without stop words is 5.6\n",
    "    ##threshold = 6\n",
    "    long_words = [word for word in text.split() if len(word)>6]\n",
    "    return sum(Counter(long_words).values())\n",
    "\n",
    "def _partOfSpeechCount(text):\n",
    "    \"\"\"\n",
    "    input: string\n",
    "    output: pos count\n",
    "    \n",
    "    \"\"\"\n",
    "    tagged_words = _nltktag(text)\n",
    "    #Noun Count\n",
    "    listnn = [w[0] for w in tagged_words if w[1] in ['NN', 'NNP', 'NNPS','NNS']]\n",
    "    nnCount = sum(Counter(listnn).values())\n",
    "    #Verb Count\n",
    "    listvb = [w[0] for w in tagged_words if w[1] in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']]\n",
    "    verbCount = sum(Counter(listvb).values())\n",
    "    #Adjective Count\n",
    "    listadj = [w[0] for w in tagged_words if w[1] in ['JJ', 'JJR', 'JJS']]\n",
    "    adjCount = sum(Counter(listadj).values())\n",
    "    #Adverb Count\n",
    "    listadvb = [w[0] for w in tagged_words if w[1] in ['RR', 'RBR', 'RBS']]\n",
    "    advbCount = sum(Counter(listadvb).values())\n",
    "    return nnCount, verbCount, adjCount, advbCount\n",
    "\n",
    "def _commaCount(text):\n",
    "    return text.count(',')\n",
    "\n",
    "def _punctuationCount(text):\n",
    "    count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "    return count(text,set(string.punctuation)) \n",
    "\n",
    "def _sentenceCount(text):\n",
    "    return len(nltk.sent_tokenize(text))\n",
    "\n",
    "def _wordLengthAvg(text):\n",
    "    l = text.split()\n",
    "    return sum(map(len, l))/float(len(l))\n",
    "\n",
    "\n",
    "\n",
    "def _spellingError(text):\n",
    "    \"\"\"\n",
    "    return: Count of misspelled words\n",
    "    \"\"\"\n",
    "    my_dict = enchant.Dict(\"en_US\")\n",
    "    my_checker = SpellChecker(my_dict)\n",
    "    my_checker.set_text(text)\n",
    "    return len([error.word for error in my_checker])\n",
    "\n",
    "def _lexicalDiversity(t):\n",
    "    \"\"\"\n",
    "    t input seq, String\n",
    "    ---------\n",
    "    return float ratio\n",
    "    \"\"\"\n",
    "    return len(set(t)) / len(t)\n",
    "\n",
    "def _quotationMark(t):\n",
    "    '''\n",
    "    t string, raw input\n",
    "    ret li, ceil of pairs of quatation contained in input text\n",
    "    '''\n",
    "    li = re.findall('\"',t)\n",
    "    n = len(li)\n",
    "    n = int(np.ceil(n/2))\n",
    "    return n\n",
    "    \n",
    "def _exclamationMarks(text):\n",
    "    return text.count('!')\n",
    "\n",
    "def _featureExtraction(text):\n",
    "    \"\"\"\n",
    "    input: essay as a long string\n",
    "    \n",
    "    output:feature vector\n",
    "    elements in output: \n",
    "    1. word count \n",
    "    2. long word count\n",
    "    3. noun word count\n",
    "    4. verb count\n",
    "    5. comma count\n",
    "    6. punctuation count\n",
    "    7. sentence count\n",
    "    8. adjective count\n",
    "    9. adverb count\n",
    "    10. lexical diversity\n",
    "    11. quatation mark\n",
    "    12. word length\n",
    "    13. spelling error\n",
    "    14*.bracket count\n",
    "    15*.exclamation count\n",
    "    16*. Foreign words count\n",
    "    \"\"\"\n",
    "    wordCount = _wordCount(text)\n",
    "    longWordCount = _longWordCount(text)\n",
    "    nounCount, verbCount, adjCount, advbCount = _partOfSpeechCount(text)\n",
    "    commaCount = _commaCount(text)\n",
    "    puncCount = _punctuationCount(text)\n",
    "    sentCount = _sentenceCount(text)\n",
    "    lexDiv = _lexicalDiversity(text)\n",
    "    quatMarkCount = _quotationMark(text)\n",
    "    avgWordLen = _wordLengthAvg(text)\n",
    "    spelErrorCount = _spellingError(text)\n",
    "    #brcktCount = _br\n",
    "    exclamationCount = _exclamationMarks(text)\n",
    "    \n",
    "    \n",
    "    f = [wordCount, longWordCount, nounCount, verbCount, commaCount, puncCount, sentCount, \n",
    "                 adjCount, advbCount, lexDiv, quatMarkCount, avgWordLen, spelErrorCount]\n",
    "    \n",
    "    return f#_res #feature vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>final_score</th>\n",
       "      <th>scaled_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          essay_set                                              essay  \\\n",
       "essay_id                                                                 \n",
       "1                 1  Dear local newspaper, I think effects computer...   \n",
       "2                 1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "3                 1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "4                 1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "5                 1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "          final_score  scaled_score  \n",
       "essay_id                             \n",
       "1                 8.0           0.6  \n",
       "2                 9.0           0.7  \n",
       "3                 7.0           0.5  \n",
       "4                10.0           0.8  \n",
       "5                 8.0           0.6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read training data\n",
    "training = pd.read_csv(\"./data/training_final_orig.csv\", sep=',',header=0, index_col=0)\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1783 essays in Topic 1.\n",
      "1800 essays in Topic 2.\n",
      "1726 essays in Topic 3.\n",
      "1771 essays in Topic 4.\n",
      "1805 essays in Topic 5.\n",
      "1800 essays in Topic 6.\n",
      "1569 essays in Topic 7.\n",
      "723 essays in Topic 8.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9):\n",
    "    print(\"{} essays in Topic {}.\".format(training[training['essay_set']==i].shape[0], i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/liuzhaopeng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/liuzhaopeng/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617.2019567489624\n"
     ]
    }
   ],
   "source": [
    "#generate feature vector for all essays\n",
    "start = time.time()\n",
    "training['f_vec'] = [_featureExtraction(essay) for essay in training['essay']]\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12977, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "* Split data to train_val, test data\n",
    "* Use Train_val data for cross-validation/forward-selection\n",
    "* Use Test data to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import pickle\n",
    "with open('training_final_train_val.pk', 'wb') as handle:\n",
    "    pickle.dump(train_val, handle)\n",
    "with open('training_final_test.pk', 'wb') as handle:\n",
    "    pickle.dump(test, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_final_train_val.pk', 'rb') as handle:\n",
    "    train_val = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data = training[training['essay_set']==1]\n",
    "t2_data = training[training['essay_set']==2]\n",
    "t3_data = training[training['essay_set']==3]\n",
    "t4_data = training[training['essay_set']==4]\n",
    "t5_data = training[training['essay_set']==5]\n",
    "t6_data = training[training['essay_set']==6]\n",
    "t7_data = training[training['essay_set']==7]\n",
    "t8_data = training[training['essay_set']==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test(X):\n",
    "    nn = int(np.ceil(len(X)*0.9))\n",
    "\n",
    "    X_train = X[0:nn]\n",
    "    X_test = X[nn:]\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_training, t1_test = split_test(t1_data)\n",
    "t2_training, t2_test = split_test(t2_data)\n",
    "t3_training, t3_test = split_test(t3_data)\n",
    "t4_training, t4_test = split_test(t4_data)\n",
    "t5_training, t5_test = split_test(t5_data)\n",
    "t6_training, t6_test = split_test(t6_data)\n",
    "t7_training, t7_test = split_test(t7_data)\n",
    "t8_training, t8_test = split_test(t8_data)\n",
    "test = pd.concat([t1_test,t2_test,t3_test,t4_test,t5_test,t6_test,t7_test,t8_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "#from sklearn.metrics import cohen_kappa_score\n",
    "from metrics import kappa\n",
    "from skll.metrics import kappa\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation without Forward Selection\n",
    "* train:val = 10 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(data_x, data_y, model):\n",
    "    # data is x\n",
    "    X_train, X_test, y_train, y_test = train_test_split(list(data_x),list(data_y), test_size=0.2)\n",
    "    \n",
    "    # define score function\n",
    "    scoring = make_scorer(kappa, weights='quadratic', allow_off_by_one=False)\n",
    "    cv=5\n",
    "    \n",
    "    # linear model\n",
    "    if model == 'lr':\n",
    "        clf = make_pipeline(preprocessing.StandardScaler(), linear_model.LinearRegression())\n",
    "        return cross_val_score(clf, X_train, y_train, cv=cv,scoring = scoring)\n",
    "\n",
    "    if model == 'svm':\n",
    "        clf = make_pipeline(preprocessing.StandardScaler(), svm.SVR(C=1))\n",
    "        return cross_val_score(clf, X_train, y_train, cv=cv,scoring = scoring)\n",
    "    \n",
    "    if model == 'rf':\n",
    "        clf = make_pipeline(preprocessing.StandardScaler(), RandomForestRegressor(max_depth=2, random_state=0))\n",
    "        return cross_val_score(clf, X_train, y_train, cv=cv,scoring = scoring)\n",
    "        \n",
    "    if model == 'adaboost':\n",
    "        clf = make_pipeline(preprocessing.StandardScaler(), AdaBoostRegressor())\n",
    "        return cross_val_score(clf, X_train, y_train, cv=cv,scoring = scoring)\n",
    "        \n",
    "    if model == 'mlp':\n",
    "        clf = make_pipeline(preprocessing.StandardScaler(), MLPRegressor())\n",
    "        return cross_val_score(clf, X_train, y_train, cv=cv,scoring = scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QWK on each validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: t0_training\n",
      "result: [ 0.79342736  0.8088748   0.83077584  0.8296578   0.81370813]\n",
      "Dataset: t1_training\n",
      "result: [ 0.67707968  0.64069557  0.71833058  0.61397299  0.66174788]\n",
      "Dataset: t2_training\n",
      "result: [ 0.6959707   0.68638153  0.62209964  0.61577667  0.61796421]\n",
      "Dataset: t3_training\n",
      "result: [ 0.65321342  0.66315823  0.66866567  0.61992973  0.61585908]\n",
      "Dataset: t4_training\n",
      "result: [ 0.79366473  0.77425461  0.76303394  0.79156389  0.79546575]\n",
      "Dataset: t5_training\n",
      "result: [ 0.62693608  0.65890088  0.6327659   0.6480367   0.66104406]\n",
      "Dataset: t6_training\n",
      "result: [ 0.65480185  0.70018328  0.6945689   0.69114     0.69616808]\n",
      "Dataset: t7_training\n",
      "result: [ 0.71550213  0.61572929  0.67051217  0.59179927  0.55019081]\n"
     ]
    }
   ],
   "source": [
    "for i,dataset in enumerate([t1_training,t2_training,t3_training,t4_training,t5_training,t6_training,t7_training,t8_training]):\n",
    "    print('Dataset: t{}_training'.format(i))\n",
    "    for model in ['lr']:\n",
    "        #print('Model: {}'.format(model))\n",
    "        \n",
    "        print('result: {}'.format(fit_predict(dataset.f_vec, dataset.final_score,model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_selection(dataset):\n",
    "    # selected features\n",
    "    selected = [] # from 0 to 12\n",
    "    # max kappa value\n",
    "    max_result = 0\n",
    "    while(1):\n",
    "        # features we will add \n",
    "        add_feature = None\n",
    "        for i in range(13):\n",
    "            temp_selected = selected.copy()\n",
    "            \n",
    "            # only select features not selected\n",
    "            if i not in selected:\n",
    "                temp_selected.append(i)\n",
    "                print('searching range: ', temp_selected)\n",
    "            \n",
    "            # calculate kappa for current feature set\n",
    "            data_x = dataset.f_vec.apply(lambda x: [x[i] for i in temp_selected])\n",
    "            data_y = dataset.final_score\n",
    "            # take mean of each fold qwk\n",
    "            temp_result = np.mean(fit_predict(data_x, data_y, model = 'lr'))\n",
    "            \n",
    "            # get better result, update\n",
    "            if temp_result>max_result:\n",
    "                add_feature = i\n",
    "                max_result = temp_result\n",
    "        \n",
    "        if add_feature != None:\n",
    "            selected.append(add_feature)\n",
    "        # \n",
    "        else:\n",
    "            break\n",
    "        print('temp_result: ', temp_result)\n",
    "        print('add_feature: ',add_feature, max_result)\n",
    "        print('*'*60)\n",
    "    return selected, max_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation with forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: t0_training\n",
      "searching range:  [0]\n",
      "searching range:  [1]\n",
      "searching range:  [2]\n",
      "searching range:  [3]\n",
      "searching range:  [4]\n",
      "searching range:  [5]\n",
      "searching range:  [6]\n",
      "searching range:  [7]\n",
      "searching range:  [8]\n",
      "searching range:  [9]\n",
      "searching range:  [10]\n",
      "searching range:  [11]\n",
      "searching range:  [12]\n",
      "temp_result:  0.128180158205\n",
      "add_feature:  0 0.75376865152\n",
      "************************************************************\n",
      "searching range:  [0, 1]\n",
      "searching range:  [0, 2]\n",
      "searching range:  [0, 3]\n",
      "searching range:  [0, 4]\n",
      "searching range:  [0, 5]\n",
      "searching range:  [0, 6]\n",
      "searching range:  [0, 7]\n",
      "searching range:  [0, 8]\n",
      "searching range:  [0, 9]\n",
      "searching range:  [0, 10]\n",
      "searching range:  [0, 11]\n",
      "searching range:  [0, 12]\n",
      "temp_result:  0.753977588462\n",
      "add_feature:  11 0.799378663748\n",
      "************************************************************\n",
      "searching range:  [0, 11, 1]\n",
      "searching range:  [0, 11, 2]\n",
      "searching range:  [0, 11, 3]\n",
      "searching range:  [0, 11, 4]\n",
      "searching range:  [0, 11, 5]\n",
      "searching range:  [0, 11, 6]\n",
      "searching range:  [0, 11, 7]\n",
      "searching range:  [0, 11, 8]\n",
      "searching range:  [0, 11, 9]\n",
      "searching range:  [0, 11, 10]\n",
      "searching range:  [0, 11, 12]\n",
      "temp_result:  0.79242005517\n",
      "add_feature:  9 0.810254891777\n",
      "************************************************************\n",
      "searching range:  [0, 11, 9, 1]\n",
      "searching range:  [0, 11, 9, 2]\n",
      "searching range:  [0, 11, 9, 3]\n",
      "searching range:  [0, 11, 9, 4]\n",
      "searching range:  [0, 11, 9, 5]\n",
      "searching range:  [0, 11, 9, 6]\n",
      "searching range:  [0, 11, 9, 7]\n",
      "searching range:  [0, 11, 9, 8]\n",
      "searching range:  [0, 11, 9, 10]\n",
      "searching range:  [0, 11, 9, 12]\n",
      "temp_result:  0.79855882653\n",
      "add_feature:  2 0.819888820041\n",
      "************************************************************\n",
      "searching range:  [0, 11, 9, 2, 1]\n",
      "searching range:  [0, 11, 9, 2, 3]\n",
      "searching range:  [0, 11, 9, 2, 4]\n",
      "searching range:  [0, 11, 9, 2, 5]\n",
      "searching range:  [0, 11, 9, 2, 6]\n",
      "searching range:  [0, 11, 9, 2, 7]\n",
      "searching range:  [0, 11, 9, 2, 8]\n",
      "searching range:  [0, 11, 9, 2, 10]\n",
      "searching range:  [0, 11, 9, 2, 12]\n",
      "temp_result:  0.825566068114\n",
      "add_feature:  12 0.825566068114\n",
      "************************************************************\n",
      "searching range:  [0, 11, 9, 2, 12, 1]\n",
      "searching range:  [0, 11, 9, 2, 12, 3]\n",
      "searching range:  [0, 11, 9, 2, 12, 4]\n",
      "searching range:  [0, 11, 9, 2, 12, 5]\n",
      "searching range:  [0, 11, 9, 2, 12, 6]\n",
      "searching range:  [0, 11, 9, 2, 12, 7]\n",
      "searching range:  [0, 11, 9, 2, 12, 8]\n",
      "searching range:  [0, 11, 9, 2, 12, 10]\n",
      "Dataset: t1_training\n",
      "searching range:  [0]\n",
      "searching range:  [1]\n",
      "searching range:  [2]\n",
      "searching range:  [3]\n",
      "searching range:  [4]\n",
      "searching range:  [5]\n",
      "searching range:  [6]\n",
      "searching range:  [7]\n",
      "searching range:  [8]\n",
      "searching range:  [9]\n",
      "searching range:  [10]\n",
      "searching range:  [11]\n",
      "searching range:  [12]\n",
      "temp_result:  0.00788389115905\n",
      "add_feature:  1 0.594159394901\n",
      "************************************************************\n",
      "searching range:  [1, 0]\n",
      "searching range:  [1, 2]\n",
      "searching range:  [1, 3]\n",
      "searching range:  [1, 4]\n",
      "searching range:  [1, 5]\n",
      "searching range:  [1, 6]\n",
      "searching range:  [1, 7]\n",
      "searching range:  [1, 8]\n",
      "searching range:  [1, 9]\n",
      "searching range:  [1, 10]\n",
      "searching range:  [1, 11]\n",
      "searching range:  [1, 12]\n",
      "temp_result:  0.562859619987\n",
      "add_feature:  9 0.659811952366\n",
      "************************************************************\n",
      "searching range:  [1, 9, 0]\n",
      "searching range:  [1, 9, 2]\n",
      "searching range:  [1, 9, 3]\n",
      "searching range:  [1, 9, 4]\n",
      "searching range:  [1, 9, 5]\n",
      "searching range:  [1, 9, 6]\n",
      "searching range:  [1, 9, 7]\n",
      "searching range:  [1, 9, 8]\n",
      "searching range:  [1, 9, 10]\n",
      "searching range:  [1, 9, 11]\n",
      "searching range:  [1, 9, 12]\n",
      "temp_result:  0.679883835527\n",
      "add_feature:  12 0.679883835527\n",
      "************************************************************\n",
      "searching range:  [1, 9, 12, 0]\n",
      "searching range:  [1, 9, 12, 2]\n",
      "searching range:  [1, 9, 12, 3]\n",
      "searching range:  [1, 9, 12, 4]\n",
      "searching range:  [1, 9, 12, 5]\n",
      "searching range:  [1, 9, 12, 6]\n",
      "searching range:  [1, 9, 12, 7]\n",
      "searching range:  [1, 9, 12, 8]\n",
      "searching range:  [1, 9, 12, 10]\n",
      "searching range:  [1, 9, 12, 11]\n",
      "temp_result:  0.684642971292\n",
      "add_feature:  3 0.703075985322\n",
      "************************************************************\n",
      "searching range:  [1, 9, 12, 3, 0]\n",
      "searching range:  [1, 9, 12, 3, 2]\n",
      "searching range:  [1, 9, 12, 3, 4]\n",
      "searching range:  [1, 9, 12, 3, 5]\n",
      "searching range:  [1, 9, 12, 3, 6]\n",
      "searching range:  [1, 9, 12, 3, 7]\n",
      "searching range:  [1, 9, 12, 3, 8]\n",
      "searching range:  [1, 9, 12, 3, 10]\n",
      "searching range:  [1, 9, 12, 3, 11]\n",
      "Dataset: t2_training\n",
      "searching range:  [0]\n",
      "searching range:  [1]\n",
      "searching range:  [2]\n",
      "searching range:  [3]\n",
      "searching range:  [4]\n",
      "searching range:  [5]\n",
      "searching range:  [6]\n",
      "searching range:  [7]\n",
      "searching range:  [8]\n",
      "searching range:  [9]\n",
      "searching range:  [10]\n",
      "searching range:  [11]\n",
      "searching range:  [12]\n",
      "temp_result:  0.0173565661258\n",
      "add_feature:  1 0.613767840648\n",
      "************************************************************\n",
      "searching range:  [1, 0]\n",
      "searching range:  [1, 2]\n",
      "searching range:  [1, 3]\n",
      "searching range:  [1, 4]\n",
      "searching range:  [1, 5]\n",
      "searching range:  [1, 6]\n",
      "searching range:  [1, 7]\n",
      "searching range:  [1, 8]\n",
      "searching range:  [1, 9]\n",
      "searching range:  [1, 10]\n",
      "searching range:  [1, 11]\n",
      "searching range:  [1, 12]\n",
      "temp_result:  0.602724313719\n",
      "add_feature:  0 0.649766204034\n",
      "************************************************************\n",
      "searching range:  [1, 0, 2]\n",
      "searching range:  [1, 0, 3]\n",
      "searching range:  [1, 0, 4]\n",
      "searching range:  [1, 0, 5]\n",
      "searching range:  [1, 0, 6]\n",
      "searching range:  [1, 0, 7]\n",
      "searching range:  [1, 0, 8]\n",
      "searching range:  [1, 0, 9]\n",
      "searching range:  [1, 0, 10]\n",
      "searching range:  [1, 0, 11]\n",
      "searching range:  [1, 0, 12]\n",
      "temp_result:  0.650237815405\n",
      "add_feature:  9 0.664325175764\n",
      "************************************************************\n",
      "searching range:  [1, 0, 9, 2]\n",
      "searching range:  [1, 0, 9, 3]\n",
      "searching range:  [1, 0, 9, 4]\n",
      "searching range:  [1, 0, 9, 5]\n",
      "searching range:  [1, 0, 9, 6]\n",
      "searching range:  [1, 0, 9, 7]\n",
      "searching range:  [1, 0, 9, 8]\n",
      "searching range:  [1, 0, 9, 10]\n",
      "searching range:  [1, 0, 9, 11]\n",
      "searching range:  [1, 0, 9, 12]\n",
      "Dataset: t3_training\n",
      "searching range:  [0]\n",
      "searching range:  [1]\n",
      "searching range:  [2]\n",
      "searching range:  [3]\n",
      "searching range:  [4]\n",
      "searching range:  [5]\n",
      "searching range:  [6]\n",
      "searching range:  [7]\n",
      "searching range:  [8]\n",
      "searching range:  [9]\n",
      "searching range:  [10]\n",
      "searching range:  [11]\n",
      "searching range:  [12]\n",
      "temp_result:  0.27628930685\n",
      "add_feature:  0 0.6174056444\n",
      "************************************************************\n",
      "searching range:  [0, 1]\n",
      "searching range:  [0, 2]\n",
      "searching range:  [0, 3]\n",
      "searching range:  [0, 4]\n",
      "searching range:  [0, 5]\n",
      "searching range:  [0, 6]\n",
      "searching range:  [0, 7]\n",
      "searching range:  [0, 8]\n",
      "searching range:  [0, 9]\n",
      "searching range:  [0, 10]\n",
      "searching range:  [0, 11]\n",
      "searching range:  [0, 12]\n",
      "temp_result:  0.615907442094\n",
      "add_feature:  1 0.647984313698\n",
      "************************************************************\n",
      "searching range:  [0, 1, 2]\n",
      "searching range:  [0, 1, 3]\n",
      "searching range:  [0, 1, 4]\n",
      "searching range:  [0, 1, 5]\n",
      "searching range:  [0, 1, 6]\n",
      "searching range:  [0, 1, 7]\n",
      "searching range:  [0, 1, 8]\n",
      "searching range:  [0, 1, 9]\n",
      "searching range:  [0, 1, 10]\n",
      "searching range:  [0, 1, 11]\n",
      "searching range:  [0, 1, 12]\n",
      "temp_result:  0.638546569059\n",
      "add_feature:  6 0.654416903452\n",
      "************************************************************\n",
      "searching range:  [0, 1, 6, 2]\n",
      "searching range:  [0, 1, 6, 3]\n",
      "searching range:  [0, 1, 6, 4]\n",
      "searching range:  [0, 1, 6, 5]\n",
      "searching range:  [0, 1, 6, 7]\n",
      "searching range:  [0, 1, 6, 8]\n",
      "searching range:  [0, 1, 6, 9]\n",
      "searching range:  [0, 1, 6, 10]\n",
      "searching range:  [0, 1, 6, 11]\n",
      "searching range:  [0, 1, 6, 12]\n",
      "Dataset: t4_training\n",
      "searching range:  [0]\n",
      "searching range:  [1]\n",
      "searching range:  [2]\n",
      "searching range:  [3]\n",
      "searching range:  [4]\n",
      "searching range:  [5]\n",
      "searching range:  [6]\n",
      "searching range:  [7]\n",
      "searching range:  [8]\n",
      "searching range:  [9]\n",
      "searching range:  [10]\n",
      "searching range:  [11]\n",
      "searching range:  [12]\n",
      "temp_result:  0.228661195216\n",
      "add_feature:  0 0.749105650459\n",
      "************************************************************\n",
      "searching range:  [0, 1]\n",
      "searching range:  [0, 2]\n",
      "searching range:  [0, 3]\n",
      "searching range:  [0, 4]\n",
      "searching range:  [0, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching range:  [0, 6]\n",
      "searching range:  [0, 7]\n",
      "searching range:  [0, 8]\n",
      "searching range:  [0, 9]\n",
      "searching range:  [0, 10]\n",
      "searching range:  [0, 11]\n",
      "searching range:  [0, 12]\n",
      "temp_result:  0.740229323722\n",
      "add_feature:  11 0.783721648791\n",
      "************************************************************\n",
      "searching range:  [0, 11, 1]\n",
      "searching range:  [0, 11, 2]\n",
      "searching range:  [0, 11, 3]\n",
      "searching range:  [0, 11, 4]\n",
      "searching range:  [0, 11, 5]\n",
      "searching range:  [0, 11, 6]\n",
      "searching range:  [0, 11, 7]\n",
      "searching range:  [0, 11, 8]\n",
      "searching range:  [0, 11, 9]\n",
      "searching range:  [0, 11, 10]\n",
      "searching range:  [0, 11, 12]\n",
      "temp_result:  0.7691740755\n",
      "add_feature:  6 0.791201654833\n",
      "************************************************************\n",
      "searching range:  [0, 11, 6, 1]\n",
      "searching range:  [0, 11, 6, 2]\n",
      "searching range:  [0, 11, 6, 3]\n",
      "searching range:  [0, 11, 6, 4]\n",
      "searching range:  [0, 11, 6, 5]\n",
      "searching range:  [0, 11, 6, 7]\n",
      "searching range:  [0, 11, 6, 8]\n",
      "searching range:  [0, 11, 6, 9]\n",
      "searching range:  [0, 11, 6, 10]\n",
      "searching range:  [0, 11, 6, 12]\n",
      "Dataset: t5_training\n",
      "searching range:  [0]\n",
      "searching range:  [1]\n",
      "searching range:  [2]\n",
      "searching range:  [3]\n",
      "searching range:  [4]\n",
      "searching range:  [5]\n",
      "searching range:  [6]\n",
      "searching range:  [7]\n",
      "searching range:  [8]\n",
      "searching range:  [9]\n",
      "searching range:  [10]\n",
      "searching range:  [11]\n",
      "searching range:  [12]\n",
      "temp_result:  0.0\n",
      "add_feature:  1 0.587906220982\n",
      "************************************************************\n",
      "searching range:  [1, 0]\n",
      "searching range:  [1, 2]\n",
      "searching range:  [1, 3]\n",
      "searching range:  [1, 4]\n",
      "searching range:  [1, 5]\n",
      "searching range:  [1, 6]\n",
      "searching range:  [1, 7]\n",
      "searching range:  [1, 8]\n",
      "searching range:  [1, 9]\n",
      "searching range:  [1, 10]\n",
      "searching range:  [1, 11]\n",
      "searching range:  [1, 12]\n",
      "temp_result:  0.597991979289\n",
      "add_feature:  7 0.611785499694\n",
      "************************************************************\n",
      "searching range:  [1, 7, 0]\n",
      "searching range:  [1, 7, 2]\n",
      "searching range:  [1, 7, 3]\n",
      "searching range:  [1, 7, 4]\n",
      "searching range:  [1, 7, 5]\n",
      "searching range:  [1, 7, 6]\n",
      "searching range:  [1, 7, 8]\n",
      "searching range:  [1, 7, 9]\n",
      "searching range:  [1, 7, 10]\n",
      "searching range:  [1, 7, 11]\n",
      "searching range:  [1, 7, 12]\n",
      "temp_result:  0.624812621882\n",
      "add_feature:  6 0.645670247779\n",
      "************************************************************\n",
      "searching range:  [1, 7, 6, 0]\n",
      "searching range:  [1, 7, 6, 2]\n",
      "searching range:  [1, 7, 6, 3]\n",
      "searching range:  [1, 7, 6, 4]\n",
      "searching range:  [1, 7, 6, 5]\n",
      "searching range:  [1, 7, 6, 8]\n",
      "searching range:  [1, 7, 6, 9]\n",
      "searching range:  [1, 7, 6, 10]\n",
      "searching range:  [1, 7, 6, 11]\n",
      "searching range:  [1, 7, 6, 12]\n",
      "temp_result:  0.656502015823\n",
      "add_feature:  12 0.656502015823\n",
      "************************************************************\n",
      "searching range:  [1, 7, 6, 12, 0]\n",
      "searching range:  [1, 7, 6, 12, 2]\n",
      "searching range:  [1, 7, 6, 12, 3]\n",
      "searching range:  [1, 7, 6, 12, 4]\n",
      "searching range:  [1, 7, 6, 12, 5]\n",
      "searching range:  [1, 7, 6, 12, 8]\n",
      "searching range:  [1, 7, 6, 12, 9]\n",
      "searching range:  [1, 7, 6, 12, 10]\n",
      "searching range:  [1, 7, 6, 12, 11]\n",
      "temp_result:  0.631667581022\n",
      "add_feature:  10 0.658126627367\n",
      "************************************************************\n",
      "searching range:  [1, 7, 6, 12, 10, 0]\n",
      "searching range:  [1, 7, 6, 12, 10, 2]\n",
      "searching range:  [1, 7, 6, 12, 10, 3]\n",
      "searching range:  [1, 7, 6, 12, 10, 4]\n",
      "searching range:  [1, 7, 6, 12, 10, 5]\n",
      "searching range:  [1, 7, 6, 12, 10, 8]\n",
      "searching range:  [1, 7, 6, 12, 10, 9]\n",
      "searching range:  [1, 7, 6, 12, 10, 11]\n",
      "Dataset: t6_training\n",
      "searching range:  [0]\n",
      "searching range:  [1]\n",
      "searching range:  [2]\n",
      "searching range:  [3]\n",
      "searching range:  [4]\n",
      "searching range:  [5]\n",
      "searching range:  [6]\n",
      "searching range:  [7]\n",
      "searching range:  [8]\n",
      "searching range:  [9]\n",
      "searching range:  [10]\n",
      "searching range:  [11]\n",
      "searching range:  [12]\n",
      "temp_result:  0.0929933185143\n",
      "add_feature:  0 0.594282069733\n",
      "************************************************************\n",
      "searching range:  [0, 1]\n",
      "searching range:  [0, 2]\n",
      "searching range:  [0, 3]\n",
      "searching range:  [0, 4]\n",
      "searching range:  [0, 5]\n",
      "searching range:  [0, 6]\n",
      "searching range:  [0, 7]\n",
      "searching range:  [0, 8]\n",
      "searching range:  [0, 9]\n",
      "searching range:  [0, 10]\n",
      "searching range:  [0, 11]\n",
      "searching range:  [0, 12]\n",
      "temp_result:  0.596442093526\n",
      "add_feature:  6 0.64501452581\n",
      "************************************************************\n",
      "searching range:  [0, 6, 1]\n",
      "searching range:  [0, 6, 2]\n",
      "searching range:  [0, 6, 3]\n",
      "searching range:  [0, 6, 4]\n",
      "searching range:  [0, 6, 5]\n",
      "searching range:  [0, 6, 7]\n",
      "searching range:  [0, 6, 8]\n",
      "searching range:  [0, 6, 9]\n",
      "searching range:  [0, 6, 10]\n",
      "searching range:  [0, 6, 11]\n",
      "searching range:  [0, 6, 12]\n",
      "temp_result:  0.633886453328\n",
      "add_feature:  9 0.663578180371\n",
      "************************************************************\n",
      "searching range:  [0, 6, 9, 1]\n",
      "searching range:  [0, 6, 9, 2]\n",
      "searching range:  [0, 6, 9, 3]\n",
      "searching range:  [0, 6, 9, 4]\n",
      "searching range:  [0, 6, 9, 5]\n",
      "searching range:  [0, 6, 9, 7]\n",
      "searching range:  [0, 6, 9, 8]\n",
      "searching range:  [0, 6, 9, 10]\n",
      "searching range:  [0, 6, 9, 11]\n",
      "searching range:  [0, 6, 9, 12]\n",
      "temp_result:  0.657393286363\n",
      "add_feature:  1 0.68039186341\n",
      "************************************************************\n",
      "searching range:  [0, 6, 9, 1, 2]\n",
      "searching range:  [0, 6, 9, 1, 3]\n",
      "searching range:  [0, 6, 9, 1, 4]\n",
      "searching range:  [0, 6, 9, 1, 5]\n",
      "searching range:  [0, 6, 9, 1, 7]\n",
      "searching range:  [0, 6, 9, 1, 8]\n",
      "searching range:  [0, 6, 9, 1, 10]\n",
      "searching range:  [0, 6, 9, 1, 11]\n",
      "searching range:  [0, 6, 9, 1, 12]\n",
      "Dataset: t7_training\n",
      "searching range:  [0]\n",
      "searching range:  [1]\n",
      "searching range:  [2]\n",
      "searching range:  [3]\n",
      "searching range:  [4]\n",
      "searching range:  [5]\n",
      "searching range:  [6]\n",
      "searching range:  [7]\n",
      "searching range:  [8]\n",
      "searching range:  [9]\n",
      "searching range:  [10]\n",
      "searching range:  [11]\n",
      "searching range:  [12]\n",
      "temp_result:  0.119418927332\n",
      "add_feature:  1 0.563873484073\n",
      "************************************************************\n",
      "searching range:  [1, 0]\n",
      "searching range:  [1, 2]\n",
      "searching range:  [1, 3]\n",
      "searching range:  [1, 4]\n",
      "searching range:  [1, 5]\n",
      "searching range:  [1, 6]\n",
      "searching range:  [1, 7]\n",
      "searching range:  [1, 8]\n",
      "searching range:  [1, 9]\n",
      "searching range:  [1, 10]\n",
      "searching range:  [1, 11]\n",
      "searching range:  [1, 12]\n",
      "temp_result:  0.56603338225\n",
      "add_feature:  6 0.600147697121\n",
      "************************************************************\n",
      "searching range:  [1, 6, 0]\n",
      "searching range:  [1, 6, 2]\n",
      "searching range:  [1, 6, 3]\n",
      "searching range:  [1, 6, 4]\n",
      "searching range:  [1, 6, 5]\n",
      "searching range:  [1, 6, 7]\n",
      "searching range:  [1, 6, 8]\n",
      "searching range:  [1, 6, 9]\n",
      "searching range:  [1, 6, 10]\n",
      "searching range:  [1, 6, 11]\n",
      "searching range:  [1, 6, 12]\n",
      "temp_result:  0.554659234167\n",
      "add_feature:  2 0.612366076211\n",
      "************************************************************\n",
      "searching range:  [1, 6, 2, 0]\n",
      "searching range:  [1, 6, 2, 3]\n",
      "searching range:  [1, 6, 2, 4]\n",
      "searching range:  [1, 6, 2, 5]\n",
      "searching range:  [1, 6, 2, 7]\n",
      "searching range:  [1, 6, 2, 8]\n",
      "searching range:  [1, 6, 2, 9]\n",
      "searching range:  [1, 6, 2, 10]\n",
      "searching range:  [1, 6, 2, 11]\n",
      "searching range:  [1, 6, 2, 12]\n",
      "temp_result:  0.580957743565\n",
      "add_feature:  9 0.623054020341\n",
      "************************************************************\n",
      "searching range:  [1, 6, 2, 9, 0]\n",
      "searching range:  [1, 6, 2, 9, 3]\n",
      "searching range:  [1, 6, 2, 9, 4]\n",
      "searching range:  [1, 6, 2, 9, 5]\n",
      "searching range:  [1, 6, 2, 9, 7]\n",
      "searching range:  [1, 6, 2, 9, 8]\n",
      "searching range:  [1, 6, 2, 9, 10]\n",
      "searching range:  [1, 6, 2, 9, 11]\n",
      "searching range:  [1, 6, 2, 9, 12]\n",
      "temp_result:  0.594712393957\n",
      "add_feature:  4 0.63507489955\n",
      "************************************************************\n",
      "searching range:  [1, 6, 2, 9, 4, 0]\n",
      "searching range:  [1, 6, 2, 9, 4, 3]\n",
      "searching range:  [1, 6, 2, 9, 4, 5]\n",
      "searching range:  [1, 6, 2, 9, 4, 7]\n",
      "searching range:  [1, 6, 2, 9, 4, 8]\n",
      "searching range:  [1, 6, 2, 9, 4, 10]\n",
      "searching range:  [1, 6, 2, 9, 4, 11]\n",
      "searching range:  [1, 6, 2, 9, 4, 12]\n",
      "temp_result:  0.606797645351\n",
      "add_feature:  3 0.645272547731\n",
      "************************************************************\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 0]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 7]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching range:  [1, 6, 2, 9, 4, 3, 10]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 11]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 12]\n",
      "temp_result:  0.635840167358\n",
      "add_feature:  5 0.657347919828\n",
      "************************************************************\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 0]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 7]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 8]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 10]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 11]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 12]\n",
      "temp_result:  0.638659035081\n",
      "add_feature:  5 0.675196802779\n",
      "************************************************************\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 0]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 7]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 8]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 10]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 11]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 12]\n",
      "temp_result:  0.619836689789\n",
      "add_feature:  2 0.680077020924\n",
      "************************************************************\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 2, 0]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 2, 7]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 2, 8]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 2, 10]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 2, 11]\n",
      "searching range:  [1, 6, 2, 9, 4, 3, 5, 5, 2, 12]\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "kappa_dict = {}\n",
    "for i,dataset in enumerate([t1_training,t2_training,t3_training,t4_training,t5_training,t6_training,t7_training,t8_training]):\n",
    "    print('Dataset: t{}_training'.format(i))\n",
    "    a,b = forward_selection(dataset)\n",
    "    result_dict['Dataset: t{}_training'.format(i)] = a\n",
    "    kappa_dict['Dataset: t{}_training'.format(i)] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dataset: t0_training': [0, 11, 9, 2, 12],\n",
       " 'Dataset: t1_training': [1, 9, 12, 3],\n",
       " 'Dataset: t2_training': [1, 0, 9],\n",
       " 'Dataset: t3_training': [0, 1, 6],\n",
       " 'Dataset: t4_training': [0, 11, 6],\n",
       " 'Dataset: t5_training': [1, 7, 6, 12, 10],\n",
       " 'Dataset: t6_training': [0, 6, 9, 1],\n",
       " 'Dataset: t7_training': [1, 6, 2, 9, 4, 3, 5, 5, 2]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dataset: t0_training': 0.82556606811417443,\n",
       " 'Dataset: t1_training': 0.70307598532160664,\n",
       " 'Dataset: t2_training': 0.6643251757640064,\n",
       " 'Dataset: t3_training': 0.65441690345151082,\n",
       " 'Dataset: t4_training': 0.7912016548334222,\n",
       " 'Dataset: t5_training': 0.65812662736749716,\n",
       " 'Dataset: t6_training': 0.68039186340976465,\n",
       " 'Dataset: t7_training': 0.68007702092374622}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: t1_testing\n",
      "0.818928699001\n",
      "Dataset: t2_testing\n",
      "0.64509394572\n",
      "Dataset: t3_testing\n",
      "0.615365764\n",
      "Dataset: t4_testing\n",
      "0.685709275051\n",
      "Dataset: t5_testing\n",
      "0.771739130435\n",
      "Dataset: t6_testing\n",
      "0.681596482792\n",
      "Dataset: t7_testing\n",
      "0.717383188306\n",
      "Dataset: t8_testing\n",
      "0.596317469537\n"
     ]
    }
   ],
   "source": [
    "test['predicted'] = None\n",
    "for i,dataset in enumerate([t1_training,t2_training,t3_training,t4_training,t5_training,t6_training,t7_training,t8_training]):\n",
    "    print('Dataset: t{}_testing'.format(i+1))\n",
    "    features = result_dict['Dataset: t{}_training'.format(i)]\n",
    "    clf = make_pipeline(preprocessing.StandardScaler(), linear_model.LinearRegression())\n",
    "    data_x = dataset.f_vec.apply(lambda x: [x[i] for i in features])\n",
    "    data_y = dataset.final_score\n",
    "    clf.fit(list(data_x), list(data_y))\n",
    "    \n",
    "    # prediction\n",
    "    test_x = test[test.essay_set==(i+1)].f_vec.apply(lambda x: [x[i] for i in features])\n",
    "    true = test[test.essay_set==(i+1)].final_score\n",
    "    pred = clf.predict(list(test_x))\n",
    "    print(kappa(true, pred, weights='quadratic'))\n",
    "    #test.loc[test.essay_set==(i+1),'predicted'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
